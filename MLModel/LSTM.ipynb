{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56c6f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# univariate lstm example\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from array import array\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfce3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing independent and dependent features\n",
    "def prepare_data(timeseries_data, n_features):\n",
    "    X, y =[],[]\n",
    "    for i in range(len(timeseries_data)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_features\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(timeseries_data)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6908d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "timeseries_data = [43000,\n",
    "43700,\n",
    "44400,\n",
    "45100,\n",
    "45800,\n",
    "46500,\n",
    "47200,\n",
    "47900,\n",
    "48600,\n",
    "49300,\n",
    "50000,\n",
    "50700,\n",
    "51400,\n",
    "52100,\n",
    "52800,\n",
    "53500,\n",
    "54200,\n",
    "54900,\n",
    "55600,\n",
    "56300,\n",
    "57100,\n",
    "57900,\n",
    "58700,\n",
    "59500,\n",
    "60300,\n",
    "61100,\n",
    "61900,\n",
    "62700,\n",
    "63500,\n",
    "64300,\n",
    "65100,\n",
    "65900,\n",
    "66700,\n",
    "67500,\n",
    "68300,\n",
    "69100,\n",
    "69900,\n",
    "71000,\n",
    "72100,\n",
    "73200,\n",
    "74300,\n",
    "75400,\n",
    "76500,\n",
    "77600,\n",
    "78700,\n",
    "79800,\n",
    "80900,\n",
    "82000,\n",
    "83100,\n",
    "84200,\n",
    "85300,\n",
    "86400,\n",
    "87500,\n",
    "88600,\n",
    "89700,\n",
    "90800,\n",
    "91900,\n",
    "93000,\n",
    "94100,\n",
    "95200,\n",
    "96300,\n",
    "97400,\n",
    "98500,\n",
    "99600,\n",
    "100700,\n",
    "101800,\n",
    "102900,\n",
    "103200,\n",
    "103500,\n",
    "103800,\n",
    "104100,\n",
    "104400,\n",
    "104700,\n",
    "105000,\n",
    "105800,\n",
    "106600,\n",
    "107400,\n",
    "108200,\n",
    "109000,\n",
    "109800,\n",
    "110600,\n",
    "111400,\n",
    "112200,\n",
    "113000,\n",
    "113800,\n",
    "114600,\n",
    "115400,\n",
    "116200,\n",
    "117000,\n",
    "118000,\n",
    "119000,\n",
    "120000,\n",
    "121000,\n",
    "122000,\n",
    "123000,\n",
    "124000,\n",
    "125000,\n",
    "126000,\n",
    "127300,\n",
    "128600,\n",
    "129900,\n",
    "131200,\n",
    "132500,\n",
    "133800,\n",
    "135100,\n",
    "136400,\n",
    "137700,\n",
    "139000,\n",
    "140300,\n",
    "141600,\n",
    "142900,\n",
    "144200,\n",
    "145500,\n",
    "146800,\n",
    "148100,\n",
    "150200,\n",
    "152300,\n",
    "154400,\n",
    "156500,\n",
    "158600,\n",
    "160700,\n",
    "162800,\n",
    "164900,\n",
    "167000,\n",
    "169100,\n",
    "171200,\n",
    "173300,\n",
    "175400,\n",
    "177500,\n",
    "179600,\n",
    "182100,\n",
    "184600,\n",
    "187100,\n",
    "189600,\n",
    "192100,\n",
    "195600,\n",
    "199100,\n",
    "202600,\n",
    "206100,\n",
    "209600,\n",
    "213100,\n",
    "216600,\n",
    "220100,\n",
    "223600,\n",
    "227100,\n",
    "230600,\n",
    "234100,\n",
    "237600,\n",
    "241100,\n",
    "244600,\n",
    "248100,\n",
    "251600,\n",
    "255100,\n",
    "258600,\n",
    "262100\n",
    "]\n",
    "\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = prepare_data(timeseries_data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1faa8025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43000  43700  44400]\n",
      " [ 43700  44400  45100]\n",
      " [ 44400  45100  45800]\n",
      " [ 45100  45800  46500]\n",
      " [ 45800  46500  47200]\n",
      " [ 46500  47200  47900]\n",
      " [ 47200  47900  48600]\n",
      " [ 47900  48600  49300]\n",
      " [ 48600  49300  50000]\n",
      " [ 49300  50000  50700]\n",
      " [ 50000  50700  51400]\n",
      " [ 50700  51400  52100]\n",
      " [ 51400  52100  52800]\n",
      " [ 52100  52800  53500]\n",
      " [ 52800  53500  54200]\n",
      " [ 53500  54200  54900]\n",
      " [ 54200  54900  55600]\n",
      " [ 54900  55600  56300]\n",
      " [ 55600  56300  57100]\n",
      " [ 56300  57100  57900]\n",
      " [ 57100  57900  58700]\n",
      " [ 57900  58700  59500]\n",
      " [ 58700  59500  60300]\n",
      " [ 59500  60300  61100]\n",
      " [ 60300  61100  61900]\n",
      " [ 61100  61900  62700]\n",
      " [ 61900  62700  63500]\n",
      " [ 62700  63500  64300]\n",
      " [ 63500  64300  65100]\n",
      " [ 64300  65100  65900]\n",
      " [ 65100  65900  66700]\n",
      " [ 65900  66700  67500]\n",
      " [ 66700  67500  68300]\n",
      " [ 67500  68300  69100]\n",
      " [ 68300  69100  69900]\n",
      " [ 69100  69900  71000]\n",
      " [ 69900  71000  72100]\n",
      " [ 71000  72100  73200]\n",
      " [ 72100  73200  74300]\n",
      " [ 73200  74300  75400]\n",
      " [ 74300  75400  76500]\n",
      " [ 75400  76500  77600]\n",
      " [ 76500  77600  78700]\n",
      " [ 77600  78700  79800]\n",
      " [ 78700  79800  80900]\n",
      " [ 79800  80900  82000]\n",
      " [ 80900  82000  83100]\n",
      " [ 82000  83100  84200]\n",
      " [ 83100  84200  85300]\n",
      " [ 84200  85300  86400]\n",
      " [ 85300  86400  87500]\n",
      " [ 86400  87500  88600]\n",
      " [ 87500  88600  89700]\n",
      " [ 88600  89700  90800]\n",
      " [ 89700  90800  91900]\n",
      " [ 90800  91900  93000]\n",
      " [ 91900  93000  94100]\n",
      " [ 93000  94100  95200]\n",
      " [ 94100  95200  96300]\n",
      " [ 95200  96300  97400]\n",
      " [ 96300  97400  98500]\n",
      " [ 97400  98500  99600]\n",
      " [ 98500  99600 100700]\n",
      " [ 99600 100700 101800]\n",
      " [100700 101800 102900]\n",
      " [101800 102900 103200]\n",
      " [102900 103200 103500]\n",
      " [103200 103500 103800]\n",
      " [103500 103800 104100]\n",
      " [103800 104100 104400]\n",
      " [104100 104400 104700]\n",
      " [104400 104700 105000]\n",
      " [104700 105000 105800]\n",
      " [105000 105800 106600]\n",
      " [105800 106600 107400]\n",
      " [106600 107400 108200]\n",
      " [107400 108200 109000]\n",
      " [108200 109000 109800]\n",
      " [109000 109800 110600]\n",
      " [109800 110600 111400]\n",
      " [110600 111400 112200]\n",
      " [111400 112200 113000]\n",
      " [112200 113000 113800]\n",
      " [113000 113800 114600]\n",
      " [113800 114600 115400]\n",
      " [114600 115400 116200]\n",
      " [115400 116200 117000]\n",
      " [116200 117000 118000]\n",
      " [117000 118000 119000]\n",
      " [118000 119000 120000]\n",
      " [119000 120000 121000]\n",
      " [120000 121000 122000]\n",
      " [121000 122000 123000]\n",
      " [122000 123000 124000]\n",
      " [123000 124000 125000]\n",
      " [124000 125000 126000]\n",
      " [125000 126000 127300]\n",
      " [126000 127300 128600]\n",
      " [127300 128600 129900]\n",
      " [128600 129900 131200]\n",
      " [129900 131200 132500]\n",
      " [131200 132500 133800]\n",
      " [132500 133800 135100]\n",
      " [133800 135100 136400]\n",
      " [135100 136400 137700]\n",
      " [136400 137700 139000]\n",
      " [137700 139000 140300]\n",
      " [139000 140300 141600]\n",
      " [140300 141600 142900]\n",
      " [141600 142900 144200]\n",
      " [142900 144200 145500]\n",
      " [144200 145500 146800]\n",
      " [145500 146800 148100]\n",
      " [146800 148100 150200]\n",
      " [148100 150200 152300]\n",
      " [150200 152300 154400]\n",
      " [152300 154400 156500]\n",
      " [154400 156500 158600]\n",
      " [156500 158600 160700]\n",
      " [158600 160700 162800]\n",
      " [160700 162800 164900]\n",
      " [162800 164900 167000]\n",
      " [164900 167000 169100]\n",
      " [167000 169100 171200]\n",
      " [169100 171200 173300]\n",
      " [171200 173300 175400]\n",
      " [173300 175400 177500]\n",
      " [175400 177500 179600]\n",
      " [177500 179600 182100]\n",
      " [179600 182100 184600]\n",
      " [182100 184600 187100]\n",
      " [184600 187100 189600]\n",
      " [187100 189600 192100]\n",
      " [189600 192100 195600]\n",
      " [192100 195600 199100]\n",
      " [195600 199100 202600]\n",
      " [199100 202600 206100]\n",
      " [202600 206100 209600]\n",
      " [206100 209600 213100]\n",
      " [209600 213100 216600]\n",
      " [213100 216600 220100]\n",
      " [216600 220100 223600]\n",
      " [220100 223600 227100]\n",
      " [223600 227100 230600]\n",
      " [227100 230600 234100]\n",
      " [230600 234100 237600]\n",
      " [234100 237600 241100]\n",
      " [237600 241100 244600]\n",
      " [241100 244600 248100]\n",
      " [244600 248100 251600]\n",
      " [248100 251600 255100]\n",
      " [251600 255100 258600]]\n",
      "[ 45100  45800  46500  47200  47900  48600  49300  50000  50700  51400\n",
      "  52100  52800  53500  54200  54900  55600  56300  57100  57900  58700\n",
      "  59500  60300  61100  61900  62700  63500  64300  65100  65900  66700\n",
      "  67500  68300  69100  69900  71000  72100  73200  74300  75400  76500\n",
      "  77600  78700  79800  80900  82000  83100  84200  85300  86400  87500\n",
      "  88600  89700  90800  91900  93000  94100  95200  96300  97400  98500\n",
      "  99600 100700 101800 102900 103200 103500 103800 104100 104400 104700\n",
      " 105000 105800 106600 107400 108200 109000 109800 110600 111400 112200\n",
      " 113000 113800 114600 115400 116200 117000 118000 119000 120000 121000\n",
      " 122000 123000 124000 125000 126000 127300 128600 129900 131200 132500\n",
      " 133800 135100 136400 137700 139000 140300 141600 142900 144200 145500\n",
      " 146800 148100 150200 152300 154400 156500 158600 160700 162800 164900\n",
      " 167000 169100 171200 173300 175400 177500 179600 182100 184600 187100\n",
      " 189600 192100 195600 199100 202600 206100 209600 213100 216600 220100\n",
      " 223600 227100 230600 234100 237600 241100 244600 248100 251600 255100\n",
      " 258600 262100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X),print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fb4fa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e46e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed47dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 6s 11ms/step - loss: 16767579136.0000\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 15873792000.0000\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15137895424.0000\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 14607134720.0000\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14075575296.0000\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13503876096.0000\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13440971776.0000\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13626858496.0000\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 12919299072.0000\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 12197534720.0000\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 11332760576.0000\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 11589391360.0000\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9350289408.0000\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7852144128.0000\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6834996736.0000\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5767286784.0000\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4695671296.0000\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3753387264.0000\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1990763392.0000\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1176068992.0000\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 564101952.0000\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 195322896.0000\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 34120784.0000\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4288433.5000\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 25111714.0000\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 36062256.0000\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 28052112.0000\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 14255749.0000\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4460102.5000\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1240100.2500\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1428113.5000\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2160185.5000\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2180150.5000\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1758350.0000\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1273951.8750\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1078012.6250\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058458.3750\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1096358.8750\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1103777.1250\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1081379.3750\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1066886.5000\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1063758.2500\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054764.2500\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055905.6250\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054343.7500\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054223.0000\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054014.5000\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053168.3750\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053755.6250\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053846.2500\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053438.0000\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053914.7500\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056555.5000\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054162.3750\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053321.2500\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054450.2500\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053412.3750\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053930.6250\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054302.1250\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055168.3750\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055147.6250\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053722.8750\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053963.3750\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053345.0000\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054365.6250\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054750.7500\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053849.0000\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053391.0000\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1053273.2500\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055279.0000\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053873.6250\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053533.0000\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1053619.1250\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056544.2500\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054989.5000\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053355.7500\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1053063.2500\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055114.1250\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054247.0000\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054151.3750\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1052776.3750\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1053877.8750\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1053993.0000\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053686.2500\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1053506.8750\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054806.8750\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055444.1250\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054388.0000\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053700.3750\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1061335.5000\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054712.3750\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053401.6250\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053749.6250\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053572.1250\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 1053576.3750\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053381.6250\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054793.1250\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053776.0000\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1053937.0000\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053967.7500\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053753.1250\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053266.7500\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053896.0000\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054007.5000\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053002.5000\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053576.7500\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054508.3750\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053990.5000\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053267.1250\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053864.6250\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053765.6250\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1062996.3750\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1054285.6250\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054342.2500\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054930.6250\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058259.0000\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053803.3750\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057857.2500\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054397.7500\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056628.8750\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055382.0000\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055919.3750\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055539.7500\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054785.1250\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1053522.1250\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053319.7500\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053270.3750\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053970.8750\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053870.1250\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053465.5000\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053625.0000\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054501.0000\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1057149.7500\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055944.0000\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1070075.2500\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055374.8750\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1059202.1250\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1060984.8750\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1056415.0000\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053287.3750\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055357.8750\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054024.5000\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1052449.5000\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054078.1250\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053662.7500\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054122.8750\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055616.2500\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052726.1250\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053125.6250\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055988.6250\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058802.0000\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1058634.1250\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055756.0000\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1053136.5000\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053016.2500\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054998.3750\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053889.6250\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053862.0000\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054261.3750\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055872.3750\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054604.0000\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055536.0000\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054187.2500\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055172.3750\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056158.5000\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052333.8750\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055205.8750\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054924.2500\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054865.3750\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052632.1250\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054013.8750\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1057287.6250\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054583.6250\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1059419.0000\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058565.1250\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054550.0000\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053842.6250\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054235.0000\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055636.7500\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055436.8750\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053234.7500\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054462.3750\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054811.0000\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057540.2500\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053592.1250\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054048.5000\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053053.2500\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058139.1250\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step - loss: 1055904.0000\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1052432.5000\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054831.6250\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056550.5000\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053091.5000\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053546.1250\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053802.0000\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1053765.1250\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1056304.6250\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1052898.5000\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054452.3750\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052854.1250\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054104.3750\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1067339.1250\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054177.5000\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058062.5000\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057495.3750\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1052905.1250\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056692.3750\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1055256.7500\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1059134.5000\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054858.0000\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1060932.8750\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057688.6250\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054413.1250\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053488.3750\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054286.0000\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055833.5000\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1054454.7500\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053710.7500\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053417.7500\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056939.8750\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054247.6250\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054897.6250\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1061248.7500\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056434.7500\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1059190.6250\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054903.2500\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1061686.8750\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055832.8750\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056695.6250\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056630.5000\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052815.0000\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1065373.1250\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054861.5000\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054637.6250\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1059923.2500\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055471.2500\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056083.6250\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1061665.1250\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054041.5000\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056180.0000\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1057233.0000\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053614.3750\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053317.8750\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053666.6250\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054731.1250\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1057763.5000\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052569.6250\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056017.3750\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1061309.3750\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1051891.0000\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055127.8750\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1062559.8750\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056695.6250\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056094.3750\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058715.8750\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052573.7500\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052682.6250\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057767.1250\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054622.7500\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056630.3750\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1056580.7500\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1062147.0000\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1060190.5000\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1067241.3750\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058156.3750\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058698.3750\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1056030.5000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054882.6250\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058029.6250\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1059550.5000\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1062192.8750\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054203.3750\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1058140.0000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052358.3750\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1063160.2500\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058831.2500\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1053156.0000\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1054585.0000\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1055521.0000\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1054034.1250\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1055445.0000\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1057382.8750\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 1055570.1250\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052610.5000\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1056634.0000\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1052823.5000\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053663.0000\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1055124.1250\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1057553.8750\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053236.2500\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1055490.0000\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1056875.7500\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1057523.6250\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1065199.0000\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1062497.8750\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1061696.7500\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1053095.2500\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1064977.2500\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1066813.0000\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1058051.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161221c1af0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc63bad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264941.44]\n",
      "1 month input [258600.     262100.     264941.4375]\n",
      "1 month output [[268437.47]]\n",
      "2 month input [262100.      264941.4375  268437.46875]\n",
      "2 month output [[271839.03]]\n",
      "3 month input [264941.44 268437.47 271839.03]\n",
      "3 month output [[275058.53]]\n",
      "4 month input [268437.47 271839.03 275058.53]\n",
      "4 month output [[278584.34]]\n",
      "5 month input [271839.03 275058.53 278584.34]\n",
      "5 month output [[282051.94]]\n",
      "6 month input [275058.53 278584.34 282051.94]\n",
      "6 month output [[285502.5]]\n",
      "7 month input [278584.34 282051.94 285502.5 ]\n",
      "7 month output [[289103.25]]\n",
      "8 month input [282051.94 285502.5  289103.25]\n",
      "8 month output [[292691.03]]\n",
      "9 month input [285502.5  289103.25 292691.03]\n",
      "9 month output [[296313.28]]\n",
      "10 month input [289103.25 292691.03 296313.28]\n",
      "10 month output [[300021.03]]\n",
      "11 month input [292691.03 296313.28 300021.03]\n",
      "11 month output [[303746.25]]\n",
      "12 month input [296313.28 300021.03 303746.25]\n",
      "12 month output [[307519.8]]\n",
      "13 month input [300021.03 303746.25 307519.8 ]\n",
      "13 month output [[311354.4]]\n",
      "14 month input [303746.25 307519.8  311354.4 ]\n",
      "14 month output [[315223.7]]\n",
      "15 month input [307519.8 311354.4 315223.7]\n",
      "15 month output [[319144.34]]\n",
      "16 month input [311354.4  315223.7  319144.34]\n",
      "16 month output [[323118.22]]\n",
      "17 month input [315223.7  319144.34 323118.22]\n",
      "17 month output [[327135.97]]\n",
      "18 month input [319144.34 323118.22 327135.97]\n",
      "18 month output [[331206.]]\n",
      "19 month input [323118.22 327135.97 331206.  ]\n",
      "19 month output [[335327.78]]\n",
      "20 month input [327135.97 331206.   335327.78]\n",
      "20 month output [[339498.6]]\n",
      "21 month input [331206.   335327.78 339498.6 ]\n",
      "21 month output [[343722.6]]\n",
      "22 month input [335327.78 339498.6  343722.6 ]\n",
      "22 month output [[347999.28]]\n",
      "23 month input [339498.6  343722.6  347999.28]\n",
      "23 month output [[352328.34]]\n",
      "24 month input [343722.6  347999.28 352328.34]\n",
      "24 month output [[356711.88]]\n",
      "25 month input [347999.28 352328.34 356711.88]\n",
      "25 month output [[361149.88]]\n",
      "26 month input [352328.34 356711.88 361149.88]\n",
      "26 month output [[365642.8]]\n",
      "27 month input [356711.88 361149.88 365642.8 ]\n",
      "27 month output [[370191.88]]\n",
      "28 month input [361149.88 365642.8  370191.88]\n",
      "28 month output [[374797.5]]\n",
      "29 month input [365642.8  370191.88 374797.5 ]\n",
      "29 month output [[379460.34]]\n",
      "30 month input [370191.88 374797.5  379460.34]\n",
      "30 month output [[384181.22]]\n",
      "31 month input [374797.5  379460.34 384181.22]\n",
      "31 month output [[388960.88]]\n",
      "32 month input [379460.34 384181.22 388960.88]\n",
      "32 month output [[393799.9]]\n",
      "33 month input [384181.22 388960.88 393799.9 ]\n",
      "33 month output [[398699.22]]\n",
      "34 month input [388960.88 393799.9  398699.22]\n",
      "34 month output [[403659.44]]\n",
      "35 month input [393799.9  398699.22 403659.44]\n",
      "35 month output [[408681.4]]\n",
      "[264941.44, 268437.47, 271839.03, 275058.53, 278584.34, 282051.94, 285502.5, 289103.25, 292691.03, 296313.28, 300021.03, 303746.25, 307519.8, 311354.4, 315223.7, 319144.34, 323118.22, 327135.97, 331206.0, 335327.78, 339498.6, 343722.6, 347999.28, 352328.34, 356711.88, 361149.88, 365642.8, 370191.88, 374797.5, 379460.34, 384181.22, 388960.88, 393799.9, 398699.22, 403659.44, 408681.4]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction for next 36 months\n",
    "x_input = np.array([255100,\n",
    "258600,\n",
    "262100])\n",
    "temp_input=list(x_input)\n",
    "lst_output=[]\n",
    "i=0\n",
    "while(i<36):\n",
    "    \n",
    "    if(len(temp_input)>3):\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} month input {}\".format(i,x_input))\n",
    "        #print(x_input)\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} month output {}\".format(i,yhat))\n",
    "        temp_input.append(yhat[0][0])\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.append(yhat[0][0])\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f52b809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43000,\n",
       " 43700,\n",
       " 44400,\n",
       " 45100,\n",
       " 45800,\n",
       " 46500,\n",
       " 47200,\n",
       " 47900,\n",
       " 48600,\n",
       " 49300,\n",
       " 50000,\n",
       " 50700,\n",
       " 51400,\n",
       " 52100,\n",
       " 52800,\n",
       " 53500,\n",
       " 54200,\n",
       " 54900,\n",
       " 55600,\n",
       " 56300,\n",
       " 57100,\n",
       " 57900,\n",
       " 58700,\n",
       " 59500,\n",
       " 60300,\n",
       " 61100,\n",
       " 61900,\n",
       " 62700,\n",
       " 63500,\n",
       " 64300,\n",
       " 65100,\n",
       " 65900,\n",
       " 66700,\n",
       " 67500,\n",
       " 68300,\n",
       " 69100,\n",
       " 69900,\n",
       " 71000,\n",
       " 72100,\n",
       " 73200,\n",
       " 74300,\n",
       " 75400,\n",
       " 76500,\n",
       " 77600,\n",
       " 78700,\n",
       " 79800,\n",
       " 80900,\n",
       " 82000,\n",
       " 83100,\n",
       " 84200,\n",
       " 85300,\n",
       " 86400,\n",
       " 87500,\n",
       " 88600,\n",
       " 89700,\n",
       " 90800,\n",
       " 91900,\n",
       " 93000,\n",
       " 94100,\n",
       " 95200,\n",
       " 96300,\n",
       " 97400,\n",
       " 98500,\n",
       " 99600,\n",
       " 100700,\n",
       " 101800,\n",
       " 102900,\n",
       " 103200,\n",
       " 103500,\n",
       " 103800,\n",
       " 104100,\n",
       " 104400,\n",
       " 104700,\n",
       " 105000,\n",
       " 105800,\n",
       " 106600,\n",
       " 107400,\n",
       " 108200,\n",
       " 109000,\n",
       " 109800,\n",
       " 110600,\n",
       " 111400,\n",
       " 112200,\n",
       " 113000,\n",
       " 113800,\n",
       " 114600,\n",
       " 115400,\n",
       " 116200,\n",
       " 117000,\n",
       " 118000,\n",
       " 119000,\n",
       " 120000,\n",
       " 121000,\n",
       " 122000,\n",
       " 123000,\n",
       " 124000,\n",
       " 125000,\n",
       " 126000,\n",
       " 127300,\n",
       " 128600,\n",
       " 129900,\n",
       " 131200,\n",
       " 132500,\n",
       " 133800,\n",
       " 135100,\n",
       " 136400,\n",
       " 137700,\n",
       " 139000,\n",
       " 140300,\n",
       " 141600,\n",
       " 142900,\n",
       " 144200,\n",
       " 145500,\n",
       " 146800,\n",
       " 148100,\n",
       " 150200,\n",
       " 152300,\n",
       " 154400,\n",
       " 156500,\n",
       " 158600,\n",
       " 160700,\n",
       " 162800,\n",
       " 164900,\n",
       " 167000,\n",
       " 169100,\n",
       " 171200,\n",
       " 173300,\n",
       " 175400,\n",
       " 177500,\n",
       " 179600,\n",
       " 182100,\n",
       " 184600,\n",
       " 187100,\n",
       " 189600,\n",
       " 192100,\n",
       " 195600,\n",
       " 199100,\n",
       " 202600,\n",
       " 206100,\n",
       " 209600,\n",
       " 213100,\n",
       " 216600,\n",
       " 220100,\n",
       " 223600,\n",
       " 227100,\n",
       " 230600,\n",
       " 234100,\n",
       " 237600,\n",
       " 241100,\n",
       " 244600,\n",
       " 248100,\n",
       " 251600,\n",
       " 255100,\n",
       " 258600,\n",
       " 262100]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a4040f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeseries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c4e232c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[264941.44,\n",
       " 268437.47,\n",
       " 271839.03,\n",
       " 275058.53,\n",
       " 278584.34,\n",
       " 282051.94,\n",
       " 285502.5,\n",
       " 289103.25,\n",
       " 292691.03,\n",
       " 296313.28,\n",
       " 300021.03,\n",
       " 303746.25,\n",
       " 307519.8,\n",
       " 311354.4,\n",
       " 315223.7,\n",
       " 319144.34,\n",
       " 323118.22,\n",
       " 327135.97,\n",
       " 331206.0,\n",
       " 335327.78,\n",
       " 339498.6,\n",
       " 343722.6,\n",
       " 347999.28,\n",
       " 352328.34,\n",
       " 356711.88,\n",
       " 361149.88,\n",
       " 365642.8,\n",
       " 370191.88,\n",
       " 374797.5,\n",
       " 379460.34,\n",
       " 384181.22,\n",
       " 388960.88,\n",
       " 393799.9,\n",
       " 398699.22,\n",
       " 403659.44,\n",
       " 408681.4]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f65ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reber60gradecsv.csv', 'w') as f:\n",
    "    writer = csv.writer(f, lineterminator = '\\n')\n",
    "    \n",
    "    for val in lst_output:\n",
    "        writer.writerow([val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a70587d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[393799.9, 398699.22, 403659.44, 408681.4]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7747cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54e7660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,155)\n",
    "day_pred=np.arange(155,165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67821d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_new,timeseries_data)\n",
    "plt.plot(day_pred,lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cc598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
